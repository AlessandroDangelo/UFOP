{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kwN5LQ6BdcKfGaysKJvmCJ05JTgqH2U0","timestamp":1698774492673}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Lab 5 - BCC406/PCC177\n","\n","## REDES NEURAIS E APRENDIZAGEM EM PROFUNDIDADE\n","\n","## Regressão Logística e Rede Neural\n","\n","### Prof. Eduardo e Prof. Pedro\n","\n","Objetivos:\n","\n","- *Overfitting*\n","- Regularização\n","\n","Data da entrega : 14/11\n","\n","- Complete o código (marcado com ToDo) e quando requisitado, escreva textos diretamente nos notebooks. Onde tiver *None*, substitua pelo seu código.\n","- Execute todo notebook e salve tudo em um PDF **nomeado** como \"NomeSobrenome-LabX.pdf\"\n","- Envie o PDF e o .ipynb via google [FORM](https://forms.gle/4zZEmmZoUywrMWF59).\n"],"metadata":{"id":"eEZvlZqVDmcd"}},{"cell_type":"markdown","source":["# *Overfitting* e *Underfitting*"],"metadata":{"id":"PjIOMjh0GK3d"}},{"cell_type":"markdown","source":["## Importando os pacotes e funções auxiliares\n"],"metadata":{"id":"JW-YwCDWGZzs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJTqqURWDX5T"},"outputs":[],"source":["import numpy as np\n","import pathlib\n","import shutil\n","import tempfile\n","\n","from  IPython import display\n","from matplotlib import pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import regularizers"]},{"cell_type":"code","source":["prop_cycle = plt.rcParams['axes.prop_cycle']\n","COLOR_CYCLE = prop_cycle.by_key()['color']\n","\n","def _smooth(values, std):\n","  \"\"\"Smooths a list of values by convolving with a Gaussian distribution.\n","  Assumes equal spacing.\n","  Args:\n","    values: A 1D array of values to smooth.\n","    std: The standard deviation of the Gaussian distribution. The units are\n","      array elements.\n","  Returns:\n","    The smoothed array.\n","  \"\"\"\n","  width = std * 4\n","  x = np.linspace(-width, width, min(2 * width + 1, len(values)))\n","  kernel = np.exp(-(x / 5)**2)\n","\n","  values = np.array(values)\n","  weights = np.ones_like(values)\n","\n","  smoothed_values = np.convolve(values, kernel, mode='same')\n","  smoothed_weights = np.convolve(weights, kernel, mode='same')\n","\n","  return smoothed_values / smoothed_weights\n","\n","class HistoryPlotter(object):\n","  \"\"\"A class for plotting a named set of Keras-histories.\n","  The class maintains colors for each key from plot to plot.\n","  \"\"\"\n","\n","  def __init__(self, metric=None, smoothing_std=None):\n","    self.color_table = {}\n","    self.metric = metric\n","    self.smoothing_std = smoothing_std\n","\n","  def plot(self, histories, metric=None, smoothing_std=None):\n","    \"\"\"Plots a {name: history} dictionary of Keras histories.\n","    Colors are assigned to the name-key, and maintained from call to call.\n","    Training metrics are shown as a solid line, validation metrics dashed.\n","    Args:\n","      histories: {name: history} a dictionary of Keras histories.\n","      metric: which metric to plot from all the histories.\n","      smoothing_std: the standard deviation of the smoothing kernel applied\n","        before plotting. The units are in array-indices.\n","    \"\"\"\n","    if metric is None:\n","      metric = self.metric\n","    if smoothing_std is None:\n","      smoothing_std = self.smoothing_std\n","\n","    for name, history in histories.items():\n","      # Remember name->color associations.\n","      if name in self.color_table:\n","        color = self.color_table[name]\n","      else:\n","        color = COLOR_CYCLE[len(self.color_table) % len(COLOR_CYCLE)]\n","        self.color_table[name] = color\n","\n","      train_value = history.history[metric]\n","      val_value = history.history['val_' + metric]\n","      if smoothing_std is not None:\n","        train_value = _smooth(train_value, std=smoothing_std)\n","        val_value = _smooth(val_value, std=smoothing_std)\n","\n","      plt.plot(\n","          history.epoch,\n","          train_value,\n","          color=color,\n","          label=name.title() + ' Train')\n","      plt.plot(\n","          history.epoch,\n","          val_value,\n","          '--',\n","          label=name.title() + ' Val',\n","          color=color)\n","\n","    plt.xlabel('Epochs')\n","    plt.ylabel(metric.replace('_', ' ').title())\n","    plt.legend()\n","\n","    plt.xlim(\n","        [0, max([history.epoch[-1] for name, history in histories.items()])])\n","    plt.grid(True)\n","\n","class EpochDots(tf.keras.callbacks.Callback):\n","  \"\"\"A simple callback that prints a \".\" every epoch, with occasional reports.\n","  Args:\n","    report_every: How many epochs between full reports\n","    dot_every: How many epochs between dots.\n","  \"\"\"\n","\n","  def __init__(self, report_every=100, dot_every=1):\n","    self.report_every = report_every\n","    self.dot_every = dot_every\n","\n","  def on_epoch_end(self, epoch, logs):\n","    if epoch % self.report_every == 0:\n","      print()\n","      print('Epoch: {:d}, '.format(epoch), end='')\n","      for name, value in sorted(logs.items()):\n","        print('{}:{:0.4f}'.format(name, value), end=',  ')\n","      print()\n","\n","    if epoch % self.dot_every == 0:\n","      print('.', end='', flush=True)\n"],"metadata":{"id":"x2Wa7-lTX7DW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Importando os dados e algumas constantes"],"metadata":{"id":"mXJ_Ho38HJcn"}},{"cell_type":"markdown","source":["Algumas constantes também podem ajudar:"],"metadata":{"id":"JVVXb5FmQ2-0"}},{"cell_type":"code","source":["FEATURES = 28\n","BATCH_SIZE = 500\n","N_VALIDATION = int(1e3)\n","N_TRAIN = int(1e4)"],"metadata":{"id":"18M3U7dZQ6P2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Iremos trabalhar com o conjunto de dados de Higgs. O objetivo não é fazer física de partículas ou se preocupar com detalhes do conjunto de dados. O importante de entender é que ele contém 11.000.000 amostras, cada um com 28 características (`FEATURES`) e um rótulo de classe binária."],"metadata":{"id":"im2EBdDLHmj0"}},{"cell_type":"code","source":["gz = tf.keras.utils.get_file('HIGGS.csv.gz', 'http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz')"],"metadata":{"id":"O8iQSL1AHL0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A classe `tf.data.experimental.CsvDataset` pode ser usada para ler registros csv diretamente de um arquivo gzip sem etapa de descompactação intermediária."],"metadata":{"id":"kkC9Y8ehHW5O"}},{"cell_type":"code","source":["ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")"],"metadata":{"id":"5TLkvam9IGD7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Essa classe de leitor de csv retorna uma lista de escalares para cada registro. A função a seguir reempacota essa lista de escalares em um par (feature_vector, label).\n","\n","O TensorFlow é mais eficiente ao operar em grandes lotes de dados. Portanto, em vez de reempacotar cada linha individualmente, criaremos um novo conjunto de Dataset que receba lotes de 10.000 exemplos, aplique a função `pack_row` a cada lote e, em seguida, divida os lotes em registros individuais:"],"metadata":{"id":"Zdhy62f2IOwB"}},{"cell_type":"code","source":["def pack_row(*row):\n","  label = row[0]\n","  features = tf.stack(row[1:],1)\n","  return features, label\n","\n","packed_ds = ds.batch(10000).map(pack_row).unbatch()"],"metadata":{"id":"ZDanUuxLIOXJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Analisando os dados lidos"],"metadata":{"id":"78bYH6FzIhzE"}},{"cell_type":"code","source":["for features,label in packed_ds.batch(1000).take(1):\n","  print(features[0])\n","  plt.hist(features.numpy().flatten(), bins = 101)"],"metadata":{"id":"9M1gmnoEIjm2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["11.000.000 de amostras é um número elevado de amostras para treino. Para essa prática, usaremos as 1.000 amostras para validação e as próximas 10.000 para treinamento.\n","\n","Usaremos os métodos `Dataset.skip` e `Dataset.take` para facilitar esse processo."],"metadata":{"id":"NT50c5xeIyKN"}},{"cell_type":"code","source":["validate_ds = packed_ds.take(N_VALIDATION).cache()\n","train_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()"],"metadata":{"id":"X9B9RstpJSPI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *Overfitting* (sobreajuste)"],"metadata":{"id":"ApSP7H5fJbE1"}},{"cell_type":"markdown","source":["A maneira mais simples de evitar o *overfitting* é começar com um modelo pequeno: um modelo com um pequeno número de parâmetros (que é determinado pelo número de camadas e o número de unidades por camada). No aprendizado profundo, o número de parâmetros que podem ser aprendidos em um modelo é geralmente chamado de \"capacidade\" do modelo.\n","\n","Intuitivamente, um modelo com mais parâmetros terá mais \"capacidade de memorização\" e, portanto, poderá aprender facilmente um mapeamento perfeito do tipo dicionário entre amostras de treinamento e seus alvos, um mapeamento sem nenhum poder de **generalização**, mas isso seria inútil ao fazer previsões em dados inéditos.\n","\n","Sempre tenha isso em mente: os modelos de aprendizado profundo tendem a ser bons em se ajustar aos dados de treinamento, mas o verdadeiro desafio é a **generalização**, não o ajuste.\n","\n","Por outro lado, se a rede tiver recursos de memorização limitados, ela não conseguirá aprender o mapeamento com tanta facilidade. Para minimizar sua perda, ele terá que aprender representações compactadas que tenham mais poder preditivo. Ao mesmo tempo, se você tornar seu modelo muito pequeno, ele terá dificuldade em se ajustar aos dados de treinamento. Há um equilíbrio entre \"capacidade demais\" e \"capacidade de menos\".\n","\n","Infelizmente, não existe uma fórmula mágica para determinar o tamanho certo ou a arquitetura do seu modelo (em termos de número de camadas ou o tamanho certo para cada camada). Você terá que experimentar usando uma série de arquiteturas diferentes.\n","\n","Para encontrar um tamanho de modelo apropriado, é melhor começar com relativamente poucas camadas e parâmetros e, em seguida, começar a aumentar o tamanho das camadas ou adicionar novas camadas até ver retornos decrescentes na perda de validação.\n","\n","Comece com um modelo simples usando apenas `layers.Dense` como linha de base, depois crie versões maiores e compare-as."],"metadata":{"id":"Vjzv68mnJfkD"}},{"cell_type":"markdown","source":["## Configurando o treinamento de modelos"],"metadata":{"id":"KDEO36-DOzoT"}},{"cell_type":"markdown","source":["Nesta prática iremos avaliar diversos modelos. Para que a análise seja facilitada, usaremos a mesma configuração para todos os modelos.\n","\n","- Muitos modelos treinam melhor se você reduzir gradualmente a taxa de aprendizado durante o treinamento. Uma forma de utilizar isso em TensorFlow é por meio dos `optimizers.schedules`, os quais variam a taxa de aprendizado ao longo do tempo. Nesta prática utilizaremos o `InverseTimeDecay`.\n","- Utilizaremos como base o otimizador `tf.keras.optimizers.Adam`, o qual usará o `InverseTimeDecay` para regular a taxa de aprendizado."],"metadata":{"id":"nKjaRaxPO26c"}},{"cell_type":"code","source":["STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE # Total de amostras de treino / Batch size\n","\n","lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n","  0.001,\n","  decay_steps=STEPS_PER_EPOCH*1000,\n","  decay_rate=1,\n","  staircase=False)\n","\n","def get_optimizer():\n","  return tf.keras.optimizers.Adam(lr_schedule)"],"metadata":{"id":"h3pfjH52JWkr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O código acima define um `schedules.InverseTimeDecay` para diminuir hiperbolicamente a taxa de aprendizado para 1/2 da taxa básica em 1.000 épocas, 1/3 em 2.000 épocas e assim por diante."],"metadata":{"id":"uK8EMvGqQsLY"}},{"cell_type":"code","source":["step = np.linspace(0,100000)\n","lr = lr_schedule(step)\n","plt.figure(figsize = (8,6))\n","plt.plot(step/STEPS_PER_EPOCH, lr)\n","plt.ylim([0,max(plt.ylim())])\n","plt.xlabel('Epoch')\n","_ = plt.ylabel('Learning Rate')"],"metadata":{"id":"_VgX2eqcP5QT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Outras Callbacks são necessárias:\n","- O treinamento para desta prática é executada por muitas épocas curtas. Para reduzir o ruído de log, use o `tfdocs.EpochDots` que simplesmente imprime `.` para cada época e um conjunto completo de métricas a cada 100 épocas.\n","\n","- Para evitar tempos de treinamento longos e desnecessários, pode-se utilizar a `callbacks.EarlyStopping`. Observe que esse retorno de chamada é definido para monitorar o `val_binary_crossentropy` , não o `val_loss` . Essa diferença será importante mais tarde.\n","- Por fim, a `callbacks.TensorBoard` para gerar logs do TensorBoard para o treinamento."],"metadata":{"id":"pccvKD8AQxBi"}},{"cell_type":"code","source":["logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n","shutil.rmtree(logdir, ignore_errors=True)\n","\n","def get_callbacks(name):\n","  return [\n","    EpochDots(),\n","    tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n","    tf.keras.callbacks.TensorBoard(logdir/name),\n","  ]"],"metadata":{"id":"o0kGBZJnSvg2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Por fim, iremos definir uma função para treinar e compilar os modelos."],"metadata":{"id":"Rd8Mio9OSxUa"}},{"cell_type":"code","source":["def compile_and_fit(model, name, max_epochs=10000):\n","  optimizer = get_optimizer()\n","  model.compile(optimizer=optimizer,\n","                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","                metrics=[tf.keras.losses.BinaryCrossentropy(\n","                             from_logits=True,\n","                             name='binary_crossentropy'),\n","                         'accuracy'])\n","\n","  model.summary()\n","\n","  history = model.fit(\n","    train_ds,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs=max_epochs,\n","    validation_data=validate_ds,\n","    callbacks=get_callbacks(name),\n","    verbose=0)\n","  return history"],"metadata":{"id":"YtmZRQmjS17c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Treinando um modelo minúsculo"],"metadata":{"id":"-2rX3mMPTH-9"}},{"cell_type":"code","source":["tiny_model = tf.keras.Sequential([\n","    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dense(1)\n","])"],"metadata":{"id":"eZSXSiZ_TK_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Criando uma variável para guardar a história dos modelos treinados."],"metadata":{"id":"W3ZQaRptTO_x"}},{"cell_type":"code","source":["size_histories = {}"],"metadata":{"id":"LA2j10XUTN37"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Treinando o nosso pequeno modelo."],"metadata":{"id":"UMIxbvYdTTRg"}},{"cell_type":"code","source":["validate_ds = validate_ds.batch(BATCH_SIZE)\n","train_ds = train_ds.shuffle(int(1e4)).repeat().batch(BATCH_SIZE)\n","\n","size_histories['Tiny'] = compile_and_fit(tiny_model, 'sizes/Tiny')"],"metadata":{"id":"MeyMjmHITXKU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Verificando o modelo"],"metadata":{"id":"FzR-BuOii7G_"}},{"cell_type":"code","source":["plotter = HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n","plotter.plot(size_histories)\n","plt.ylim([0.5, 0.7])"],"metadata":{"id":"0or8Dr3mi5TX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As linhas sólidas mostram a `loss` de treinamento e as linhas tracejadas mostram a `loss` de validação (lembre-se: uma `loss` de validação menor indica um modelo melhor)."],"metadata":{"id":"h44kLLFzEd2A"}},{"cell_type":"markdown","metadata":{"id":"LGxGzh_FWOJ8"},"source":["## Treinando um modelo pequeno"]},{"cell_type":"markdown","metadata":{"id":"YjMb6E72f2pN"},"source":["Uma forma de tentar superar o desempenho do modelo minúsculo é treinando progressivamente alguns modelos maiores.\n","\n","No modelo minúsculo usamos somente uma camada de 16 neurônios. Vamos experimentar com duas camadas ocultas com 16 unidades."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKgdXPx9usBa"},"outputs":[],"source":["small_model = tf.keras.Sequential([\n","    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dense(16, activation='elu'),\n","    layers.Dense(1)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqG3MXF5xSjR"},"outputs":[],"source":["size_histories['Small'] = compile_and_fit(small_model, 'sizes/Small')"]},{"cell_type":"markdown","source":["### Verificando ambos modelos treinados"],"metadata":{"id":"EY5XjDusBtDH"}},{"cell_type":"code","source":["plotter = HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n","plotter.plot(size_histories)\n","plt.ylim([0.5, 0.7])"],"metadata":{"id":"gBsOGlrMBvJv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-DGRBbGxI6G"},"source":["## Treinando um modelo médio"]},{"cell_type":"markdown","metadata":{"id":"SrfoVQheYSO5"},"source":["Vamos tentar agora um modelo com 3 camadas e 64 neurônios por camada (quatro vezes mais)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jksi-XtaxDAh"},"outputs":[],"source":["medium_model = tf.keras.Sequential([\n","    layers.Dense(64, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dense(64, activation='elu'),\n","    layers.Dense(64, activation='elu'),\n","    layers.Dense(1)\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ofn1AwDhx-Fe"},"outputs":[],"source":["size_histories['Medium']  = compile_and_fit(medium_model, \"sizes/Medium\")"]},{"cell_type":"markdown","source":["### Verificando os modelos treinados"],"metadata":{"id":"-nWl9OjgC_4P"}},{"cell_type":"code","source":["plotter = HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n","plotter.plot(size_histories)\n","plt.ylim([0.5, 0.7])"],"metadata":{"id":"YXKoPIfPC_4R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vIPuf23FFaVn"},"source":["## Treinando um modelo grande"]},{"cell_type":"markdown","source":["Você pode criar um modelo ainda maior e verificar a rapidez com que ele começa a fazer overfitting. O novo modelo possui mais camadas e mais neurônios por camada (512)."],"metadata":{"id":"YZHIx_34DfDw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghQwwqwqvQM9"},"outputs":[],"source":["large_model = tf.keras.Sequential([\n","    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dense(1)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1A99dhqvepf"},"outputs":[],"source":["size_histories['large'] = compile_and_fit(large_model, \"sizes/large\")\n"]},{"cell_type":"markdown","metadata":{"id":"Fy3CMUZpzH3d"},"source":["### Verificando os modelos treinados"]},{"cell_type":"markdown","metadata":{"id":"OLhL1AszdLfM"},"source":["Embora a construção de um modelo maior lhe dê mais poder, se esse poder não for restringido de alguma forma, ele pode facilmente se ajustar ao conjunto de treinamento.\n","\n","Neste exemplo, normalmente, apenas o modelo minúsculo (`\"Tiny\"`) consegue evitar completamente o overfitting, e cada um dos modelos maiores superajusta os dados mais rapidamente. Isso se torna tão grave para o modelo grande (`\"Large\"`) que você precisa mudar o gráfico para uma escala logarítmica para realmente descobrir o que está acontecendo.\n","\n","Isso fica aparente se você plotar e comparar as métricas de validação com as métricas de treinamento.\n","\n","* É normal que haja uma pequena diferença.\n","* Se ambas as métricas estiverem se movendo na mesma direção, está tudo bem.\n","* Se a métrica de validação começar a estagnar enquanto a métrica de treinamento continua a melhorar, você provavelmente está perto do overfitting.\n","* Se a métrica de validação estiver indo na direção errada, o modelo está claramente superajustado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XmKDtOWzOpk"},"outputs":[],"source":["plotter.plot(size_histories)\n","a = plt.xscale('log')\n","plt.xlim([5, max(plt.xlim())])\n","plt.ylim([0.5, 0.7])\n","plt.xlabel(\"Epochs [Log Scale]\")"]},{"cell_type":"markdown","metadata":{"id":"UekcaQdmZxnW"},"source":["Todas as execuções de treinamento acima usaram o `callbacks.EarlyStopping` para encerrar o treinamento, uma vez que ficou claro que o modelo não estava progredindo."]},{"cell_type":"markdown","source":["## **ToDo:** Avaliando um modelo gigante (10pt)"],"metadata":{"id":"iVsqxHHvFofI"}},{"cell_type":"markdown","source":["Adicione a esse *benchmark* uma rede que tenha muito mais capacidade, muito mais do que o problema precisa."],"metadata":{"id":"ZxR7VuwZF1bQ"}},{"cell_type":"code","source":["### Seu código aqui\n","large_model = tf.keras.Sequential([\n","    layers.Dense(1024, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dense(1024, activation='elu'),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dense(1)\n","])"],"metadata":{"id":"dbFwRC8WFyCc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **ToDo:** Avalie o seu modelo treinado conforme foi feito nos exemplos anteriores (10pt)\n"],"metadata":{"id":"o_lGluZXF6Bp"}},{"cell_type":"markdown","source":["` É um modelo grande, com camadas de pouca variação, decorrente disso demora a ser processado. `\n","\n","> Bloco com recuo\n","\n"],"metadata":{"id":"j410xeQ65SEn"}},{"cell_type":"markdown","source":[],"metadata":{"id":"YwrIttU1zkEH"}},{"cell_type":"markdown","metadata":{"id":"DEQNKadHA0M3"},"source":["## Avaliando os resultados no *TensorBoard*"]},{"cell_type":"markdown","source":["Salvamos os logs do TensorBoard durante o treinamento de todos os modelos treinados.\n","\n","Podemos abrir um visualizador TensorBoard incorporado em um notebook."],"metadata":{"id":"wilzpr4yGJN6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6oa1lkJddZ-m"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Open an embedded TensorBoard viewer\n","%tensorboard --logdir {logdir}/sizes"]},{"cell_type":"markdown","source":["### **ToDo:** Análises (10pt)"],"metadata":{"id":"7zH8MyWZ36zn"}},{"cell_type":"markdown","source":["Quais análises você pode fazer sobre o TensorBoard?\n","\n","`É possivel percerber que os graficos de acuracia e de crossentropy são praticamente  opostos. Alem de que a taxa de learning rate decai ao longo das eras. A peca segue o grafico de crossentropy. `"],"metadata":{"id":"ElGAev0p3_V_"}},{"cell_type":"markdown","metadata":{"id":"ASdv7nsgEFhx"},"source":["# Estratégias para previnir *overfitting* (sobreajuste)"]},{"cell_type":"markdown","metadata":{"id":"YN512ksslaxJ"},"source":["Antes de entrar no conteúdo desta seção, copie os logs de treinamento do modelo minúsculo (`\"Tiny\"`) acima, para usar como linha de base para comparação.\n","\n","Iremos comparar os logs de treinamento do modelo minúsculo (`\"Tiny\"`) acima, por isso iremos copiar os logs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40k1eBtnQzNo"},"outputs":[],"source":["shutil.rmtree(logdir/'regularizers/Tiny', ignore_errors=True)\n","shutil.copytree(logdir/'sizes/Tiny', logdir/'regularizers/Tiny')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFWMeFo7jLpN"},"outputs":[],"source":["regularizer_histories = {}\n","regularizer_histories['Tiny'] = size_histories['Tiny']"]},{"cell_type":"markdown","metadata":{"id":"4rHoVWcswFLa"},"source":["### Adicionando estratégias de regularização ao modelo\n"]},{"cell_type":"markdown","metadata":{"id":"kRxWepNawbBK"},"source":["Você pode estar familiarizado com o princípio da Navalha de Occam: dadas duas explicações para algo, a explicação mais provável de ser correta é a **mais simples**, aquela que faz a menor quantidade de suposições. Isso também se aplica aos modelos aprendidos pelas redes neurais: dados alguns dados de treinamento e uma arquitetura de rede, existem vários conjuntos de valores de pesos (múltiplos modelos) que podem explicar os dados, e modelos mais simples são menos propensos a sobreajustar do que os complexos.\n","\n","Um \"modelo simples\" neste contexto é um modelo onde a distribuição de valores de parâmetros tem menos entropia (ou um modelo com menos parâmetros, como demonstrado na seção acima). Assim, uma maneira comum de mitigar o *overfitting* é colocar restrições na complexidade de uma rede, forçando seus pesos apenas a assumir valores pequenos, o que torna a distribuição de valores de peso mais \"regular\". Isso é chamado de \"regularização de peso\", e é feito adicionando à função de perda da rede um custo associado a ter grandes pesos. Este custo vem em dois sabores:\n","\n","* [Regularização L1](https://developers.google.com/machine-learning/glossary/#L1_regularization), onde o custo adicionado é proporcional ao valor absoluto dos coeficientes dos pesos (ou seja, ao que é chamado de \"norma L1 \"dos pesos).\n","\n","* [Regularização L2](https://developers.google.com/machine-learning/glossary/#L2_regularization), onde o custo adicionado é proporcional ao quadrado do valor dos coeficientes dos pesos (ou seja, ao que é chamado de quadrado \"norma L2\" dos pesos). A regularização L2 também é chamada de decaimento de peso no contexto de redes neurais. Não deixe que o nome diferente o confunda: a redução de peso (*weight decay*) é matematicamente igual à regularização L2.\n","\n","A regularização L1 empurra os pesos para zero, incentivando um modelo esparso. A regularização de L2 penalizará os parâmetros de pesos sem torná-los esparsos, já que a penalidade vai para zero para pesos pequenos - uma razão pela qual L2 é mais comum.\n","\n","Em `tf.keras`, a regularização de peso é adicionada passando instâncias do regularizador de peso para camadas como argumentos de palavras-chave. Adicione regularização de peso L2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFGmcwduwVyQ"},"outputs":[],"source":["l2_model = tf.keras.Sequential([\n","    layers.Dense(512, activation='elu', kernel_regularizer=regularizers.l2(0.001), input_shape=(FEATURES,)),\n","    layers.Dense(512, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n","    layers.Dense(512, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n","    layers.Dense(512, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n","    layers.Dense(1)\n","])\n","\n","regularizer_histories['l2'] = compile_and_fit(l2_model, \"regularizers/l2\")"]},{"cell_type":"markdown","metadata":{"id":"bUUHoXb7w-_C"},"source":["`l2(0,001)` significa que cada coeficiente na matriz de peso da camada adicionará `0,001 * weight_coeficiente_value**2` ao total de **perda** da rede.\n","\n","É por isso que estamos monitorando o `binary_crossentropy` diretamente. Porque não tem esse componente de regularização misturado.\n","\n","Então, esse mesmo modelo `\"Large\"` com uma penalidade de regularização `L2` tem um desempenho muito melhor:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wkfLyxBZdh_"},"outputs":[],"source":["plotter.plot(regularizer_histories)\n","plt.ylim([0.5, 0.7])"]},{"cell_type":"markdown","metadata":{"id":"Kx1YHMsVxWjP"},"source":["Conforme demonstrado, o modelo regularizado `\"L2\"` agora é muito mais competitivo com o modelo `\"Tiny\"`. Este modelo `\"L2\"` também é muito mais resistente ao overfitting do que o modelo `\"Large\"` no qual foi baseado, apesar de ter o mesmo número de parâmetros."]},{"cell_type":"markdown","source":["### Adicionando *dropout*"],"metadata":{"id":"jmgsvrBo4h9u"}},{"cell_type":"markdown","metadata":{"id":"HmnBNOOVxiG8"},"source":["Dropout é uma das técnicas de regularização mais eficazes e mais utilizadas para redes neurais, desenvolvida por Hinton e seus alunos da Universidade de Toronto.\n","\n","A explicação intuitiva para o dropout é que, como os nós individuais na rede não podem contar com a saída dos outros, cada nó deve produzir recursos que sejam úteis por conta própria.\n","\n","O dropout, aplicado a uma camada, consiste em \"descartar\" aleatoriamente (ou seja, definir como zero) um número de recursos de saída da camada durante o treinamento. Por exemplo, uma determinada camada normalmente retornaria um vetor `[0.2, 0.5, 1.3, 0.8, 1.1]` para uma determinada amostra de entrada durante o treinamento; após aplicar dropout, este vetor terá algumas entradas zero distribuídas aleatoriamente, por exemplo. `[0, 0,5, 1,3, 0, 1,1]`.\n","\n","A \"taxa de abandono\" é a fração dos recursos que estão sendo zerados; geralmente é definido entre 0,2 e 0,5. No momento do teste, nenhuma unidade é descartada e, em vez disso, os valores de saída da camada são reduzidos por um fator igual à taxa de abandono, de modo a equilibrar o fato de que mais unidades estão ativas do que no tempo de treinamento.\n","\n","No Keras, você pode introduzir dropout em uma rede através da camada `tf.keras.layers.Dropout`, que é aplicada à saída da camada imediatamente anterior.\n","\n","Adicione duas camadas de dropout à sua rede para verificar o desempenho delas na redução do overfitting:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFEYvtrHxSWS"},"outputs":[],"source":["dropout_model = tf.keras.Sequential([\n","    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(1)\n","])\n","\n","regularizer_histories['dropout'] = compile_and_fit(dropout_model, \"regularizers/dropout\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPZqwVchx5xp"},"outputs":[],"source":["plotter.plot(regularizer_histories)\n","plt.ylim([0.5, 0.7])"]},{"cell_type":"markdown","metadata":{"id":"4zlHr4iaI1U6"},"source":["Fica claro neste gráfico que ambas as abordagens de regularização melhoram o comportamento do modelo grande (`\"Large\"`). Mas isso ainda não supera nem mesmo a linha de base `\"Tiny\"`.\n","\n","Naturalmente, o próximo passo é testar os dois juntos."]},{"cell_type":"markdown","metadata":{"id":"u7qMg_7Nwy5t"},"source":["### Combinando L2 + *dropout*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zfs_qQIw1cz"},"outputs":[],"source":["combined_model = tf.keras.Sequential([\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu', input_shape=(FEATURES,)),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(1)\n","])\n","\n","regularizer_histories['combined'] = compile_and_fit(combined_model, \"regularizers/combined\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDqBBxfI0Yd8"},"outputs":[],"source":["# @title Default title text\n","plotter.plot(regularizer_histories)\n","plt.ylim([0.5, 0.7])"]},{"cell_type":"markdown","metadata":{"id":"tE0OoNCQNTJv"},"source":["Este modelo com as regularizações combinadas (`\"Combined\"`) é obviamente o melhor até agora."]},{"cell_type":"code","source":[],"metadata":{"id":"mKtkBzV91HbB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dw23T03FEO1"},"source":["### Avaliando os resultados no *TensorBoard*\n"]},{"cell_type":"markdown","source":["Esses modelos também registraram logs do TensorBoard.\n","\n","Para abrir um visualizador de tensorboard incorporado em um notebook, copie o seguinte em uma célula de código:\n","\n","```\n","%tensorboard --logdir {logdir}/regularizers\n","```"],"metadata":{"id":"tkfn3OVNMWgy"}},{"cell_type":"code","source":["%tensorboard --logdir {logdir}/regularizers"],"metadata":{"id":"8gxPkdfX1JLf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **ToDo:** Análise dos resultados (10pt)"],"metadata":{"id":"o4gUY3OE8MbI"}},{"cell_type":"markdown","source":["O que você pode inferir analisando os resultados apresentados no TensorBoard?\n","\n","` É possivel perceber a diferença de cada metodo e como a divergencia de tamanho implica nos resultados graficos, alem dos outros metodos de avaliação `"],"metadata":{"id":"Ag9J3mSu8QxY"}},{"cell_type":"markdown","source":["# Avaliando estrátegias de *overfitting* e regularização para a base de gato/não-gato"],"metadata":{"id":"KnD92jS94n2-"}},{"cell_type":"markdown","source":["Para essa próxima tarefa, avalie três modelos (semelhante ao que foi feito para a base de Higgs). Você deve treinar:\n","- Um modelo pequeno.\n","- Um modelo médio.\n","- Um modelo grande."],"metadata":{"id":"j27RftDF5ite"}},{"cell_type":"markdown","source":["Criando uma variável para guardar a história dos modelos treinados."],"metadata":{"id":"NqgRCGID5X4x"}},{"cell_type":"code","source":["cat_histories = {}"],"metadata":{"id":"4y8MOo3l5X4x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **ToDo:** Lendo os dados da base de gatos/não-gatos (10pt)"],"metadata":{"id":"34arspfN48kH"}},{"cell_type":"code","source":["### Seu código aqui\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","def load_dataset():\n","    def _load_data():\n","      train_dataset = h5py.File('drive/MyDrive/train_catvnoncat.h5', \"r\")\n","      train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n","      train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n","\n","      test_dataset = h5py.File('drive/MyDrive/test_catvnoncat.h5', \"r\")\n","      test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n","      test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n","\n","      classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n","      train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n","      test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n","\n","      return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n","\n","    def _preprocess_dataset(_treino_x_orig, _teste_x_orig):\n","      # Formate o conjunto de treinamento e teste dados de treinamento e teste para que as imagens\n","      # de tamanho (num_px, num_px, 3) sejam vetores de forma (num_px * num_px * 3, 1)\n","      _treino_x_vet = _treino_x_orig.reshape(_treino_x_orig.shape[0], -1) # ToDo: vetorizar os dados de treinamento aqui\n","      _teste_x_vet = _teste_x_orig.reshape(_teste_x_orig.shape[0], -1) # ToDo: vetorizar os dados de teste aqui\n","\n","      # Normalize os dados (colocar no intervalo [0.0, 1.0])\n","      _treino_x = _treino_x_vet/255. # ToDo: normalize os dados de treinamento aqui\n","      _teste_x = _teste_x_vet/255. # ToDo: normalize os dados de teste aqui\n","      return _treino_x, _teste_x\n","\n","    treino_x_orig, treino_y, teste_x_orig, teste_y, classes = _load_data()\n","    treino_x, teste_x = _preprocess_dataset(treino_x_orig, teste_x_orig)\n","    return treino_x, treino_y, teste_x, teste_y, classes"],"metadata":{"id":"YotyGtWV5Gy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lendo os dados (gato/não-gato)\n","treino_x, treino_y, teste_x, teste_y, classes = load_dataset()"],"metadata":{"id":"u2RfAjkf57dH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n","shutil.rmtree(logdir, ignore_errors=True)\n","\n","def get_callbacks(name):\n","  return [\n","    EpochDots(),\n","    tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n","    tf.keras.callbacks.TensorBoard(logdir/name),\n","  ]"],"metadata":{"id":"n-HGlnSz6Afw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compile_and_fit_cat(model, name, max_epochs=10000):\n","  optimizer = get_optimizer()\n","  model.compile(optimizer=optimizer,\n","                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","                metrics=[tf.keras.losses.BinaryCrossentropy(\n","                             from_logits=True,\n","                             name='binary_crossentropy'),\n","                         'accuracy'])\n","\n","  model.summary()\n","\n","  history = model.fit(\n","    treino_x,\n","    treino_y.reshape(-1),\n","    validation_split = 0.1,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs=max_epochs,\n","    callbacks=get_callbacks(name),\n","    verbose=0)\n","  return history"],"metadata":{"id":"Yvy7jZ6l6Cmt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YNrAMNDT5X4y"},"source":["## **ToDo:** Treinando um modelo pequeno (10pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q7jmcW_65X4y"},"outputs":[],"source":["modelo_pequeno = tf.keras.Sequential([\n","    layers.Dense(16, activation='elu', input_shape=(12288,)),\n","    layers.Dense(16, activation='elu'),\n","    layers.Dense(1)\n","])\n","cat_histories['Pequeno'] = compile_and_fit_cat(modelo_pequeno, 'sizes/Pequeno')"]},{"cell_type":"markdown","metadata":{"id":"Tauy-P8h5X4y"},"source":["## **ToDo:** Treinando um modelo médio (10pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8-qF5PP5X4z"},"outputs":[],"source":["modelo_medio = tf.keras.Sequential([\n","    layers.Dense(64, activation='elu', input_shape=(12288,)),\n","    layers.Dense(64, activation='elu'),\n","    layers.Dense(64, activation='elu'),\n","    layers.Dense(1)\n","])\n","cat_histories['Medio'] = compile_and_fit_cat(modelo_medio, 'sizes/Medio')"]},{"cell_type":"markdown","metadata":{"id":"k8roVOCn5X4z"},"source":["## **ToDo:** Treinando um modelo grande (10pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIYJL4zR5X4z"},"outputs":[],"source":["modelo_grande = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","cat_histories['Grande'] = compile_and_fit(modelo_pequeno, 'sizes/Grande')"]},{"cell_type":"markdown","metadata":{"id":"c0MI5bjy63pR"},"source":["## **ToDo:** Avalie a adição de regularização aos modelos (10pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iklh3o0j63pS"},"outputs":[],"source":["modelo_com_regularizacao = tf.keras.Sequential([\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu', input_shape=(12288,)),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n","                 activation='elu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(1)\n","])\n","cat_histories['Regularizacao'] = compile_and_fit_cat(modelo_com_regularizacao, 'sizes/Regularizacao')"]},{"cell_type":"markdown","source":["## Resultados do treinamento"],"metadata":{"id":"9LAJy6l98rLI"}},{"cell_type":"code","source":["plotter.plot(cat_histories)\n","# plt.ylim([0.5, 0.7])"],"metadata":{"id":"NaG4XKr48tpQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **ToDo:** Análise dos resultados (10pt)"],"metadata":{"id":"x40CjnzR8geU"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","y_pred_pequeno = modelo_pequeno.predict(teste_x)\n","y_pred_pequeno = (y_pred_pequeno > 0.5).astype(int)\n","y_pred_pequeno = y_pred_pequeno.reshape((50,))\n","report_pequeno = classification_report(teste_y[0], y_pred_pequeno, target_names=classes)\n","print(\"Relatório de classificação para o modelo Pequeno:\\n\", report_pequeno)\n","\n","y_pred_medio = modelo_medio.predict(teste_x)\n","y_pred_medio = (y_pred_medio > 0.5).astype(int)\n","y_pred_medio = y_pred_medio.reshape((50,))\n","report_medio = classification_report(teste_y[0], y_pred_medio, target_names=classes)\n","print(\"Relatório de classificação para o modelo Médio:\\n\", report_medio)\n","\n","y_pred_grande = modelo_grande.predict(teste_x)\n","y_pred_grande = (y_pred_grande > 0.5).astype(int)\n","y_pred_grande = y_pred_grande.reshape((50,))\n","report_grande = classification_report(teste_y[0], y_pred_grande, target_names=classes)\n","print(\"Relatório de classificação para o modelo Grande:\\n\", report_grande)\n","\n","y_pred_regularizacao = modelo_com_regularizacao.predict(teste_x)\n","y_pred_regularizacao = (y_pred_regularizacao > 0.5).astype(int)\n","y_pred_regularizacao = y_pred_regularizacao.reshape((50,))\n","report_regularizacao = classification_report(teste_y[0], y_pred_regularizacao, target_names=classes)\n","print(\"Relatório de classificação para o modelo com Regularização:\\n\", report_regularizacao)\n"],"metadata":{"id":"fUGIFQ1JUx51"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Avalia os modelos treinados quanto a Acurácia, F1-score, Precisão e revocação.\n","\n","Dica: utilize a função [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) da sklearn."],"metadata":{"id":"8z1sJ3G8I11k"}},{"cell_type":"markdown","source":["O que você pode inferir analisando os resultados dos treinamentos para a base de gatos/não-gatos.\n","\n","` Se destaca o fato de que a precisão de acerto de não gatos dos metodos está abaixo da media, o que revela um problema,  em\n","contrapartida a própria precisão de acerto de gatos está alta, o que pode ser fruto de um mecanismo de categorizar como não gato em caso de duvida. Alinhado a tudo\n","isso, os melhores resultados são de recall `"],"metadata":{"id":"UhyPvDvX8gel"}}]}